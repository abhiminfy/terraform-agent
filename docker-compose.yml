

services:
  redis:
    image: redis:7
    container_name: redis
    ports: ["6379:6379"]

  api:
    build: ./backend
    container_name: backend-api
    env_file:
      - ./backend/.env
    environment:
      CELERY_BROKER_URL: redis://redis:6379/1
      CELERY_RESULT_BACKEND: redis://redis:6379/2
      JWT_ALG: HS256
      APP_VERSION: 1.0.0
      # allow the WebUI (http://localhost:3000) to call the API
      ALLOWED_ORIGINS: "http://localhost:3000,http://127.0.0.1:3000,*"
    volumes:
      - ./backend:/app
    ports: ["8000:8000"]
    depends_on: [redis]

  worker:
    build: ./backend
    container_name: backend-worker
    command: celery -A background.celery_app worker -l info --concurrency=2
    env_file:
      - ./backend/.env
    environment:
      CELERY_BROKER_URL: redis://redis:6379/1
      CELERY_RESULT_BACKEND: redis://redis:6379/2
      JWT_SECRET: change-me
      JWT_ALG: HS256
    volumes:
      - ./backend:/app
    depends_on: [redis]

  # Fixed: Open WebUI configured for OpenAI-compatible mode
  webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    environment:
      # Disable Ollama completely
      ENABLE_OLLAMA_API: false
      OLLAMA_BASE_URL: ""

      # Configure OpenAI mode
      OPENAI_API_KEY: "local-key"
      OPENAI_API_BASE_URL: "http://api:8000/v1"

      # Optional: Disable other model providers
      ENABLE_OPENAI_API: true

      # UI Configuration
      WEBUI_NAME: "Terraform Agent"
      DEFAULT_MODELS: "terraform-agent"
      DEFAULT_USER_ROLE: "user"

      # Security (optional)
      WEBUI_SECRET_KEY: "your-secret-key-change-me"

    ports: ["3000:8080"]
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - api

volumes:
  open-webui:
